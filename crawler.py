from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import json
from datetime import datetime
import time
import random
import pytz

# å­˜å‚¨æ‰€æœ‰ç»“æœ
all_results = []

# é…ç½®
base_url = "https://www.gamer520.com/switchyouxi"
pages_to_crawl = 5  # æŠ“å–å‰5é¡µ
timeout = 40000  # å¢åŠ è¶…æ—¶æ—¶é—´
max_retries = 3  # å•é¡µæœ€å¤§é‡è¯•æ¬¡æ•°

# å¯åŠ¨æµè§ˆå™¨
with sync_playwright() as p:
    browser = p.chromium.launch(
        headless=True,
        args=[
            '--disable-blink-features=AutomationControlled',
            '--no-sandbox',
            '--disable-dev-shm-usage'
        ]
    )
    
    context = browser.new_context(
        user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
        viewport={'width': 1920, 'height': 1080},
        # å±è”½å›¾ç‰‡å’Œå­—ä½“åŠ è½½åŠ é€Ÿ
        bypass_csp=True
    )
    page = context.new_page()

    for page_num in range(1, pages_to_crawl + 1):
        url = f"{base_url}/page/{page_num}" if page_num > 1 else base_url
        print(f"\n=== æ­£åœ¨æŠ“å–ç¬¬ {page_num} é¡µ ===")

        retry_count = 0
        while retry_count < max_retries:
            try:
                # è®¿é—®é¡µé¢ï¼ˆå¼ºåˆ¶ç­‰å¾…å®Œå…¨åŠ è½½ï¼‰
                page.goto(url, timeout=timeout, wait_until="networkidle")
                page.wait_for_load_state("load", timeout=timeout)

                # æ£€æŸ¥æ˜¯å¦è¢«æ‹¦æˆª
                if "anti-bot" in page.content().lower():
                    raise Exception("æ£€æµ‹åˆ°åçˆ¬éªŒè¯")

                # æ»šåŠ¨é¡µé¢ï¼ˆæ¨¡æ‹Ÿäººå·¥æ“ä½œï¼‰
                for _ in range(3):
                    page.evaluate("window.scrollBy(0, window.innerHeight * 0.8)")
                    time.sleep(random.uniform(0.5, 2))

                # ç­‰å¾…å†…å®¹åŠ è½½
                page.wait_for_selector("article:has(h2)", timeout=15000)
                html = page.content()

                # è§£ææ•°æ®
                soup = BeautifulSoup(html, 'html.parser')
                game_items = soup.find_all('article', class_=lambda x: x and ('post' in x or 'grid' in x))
                print(f"æ‰¾åˆ° {len(game_items)} ä¸ªæ¸¸æˆæ¡ç›®")

                for item in game_items:
                    try:
                        title = item.find('h2').get_text().strip()
                        link = item.find('a')['href']
                        
                        # å¤„ç†æ—¥æœŸï¼ˆå…¼å®¹å¤šç§æ ¼å¼ï¼‰
                        time_tag = item.find('time')
                        date_str = time_tag['datetime'] if time_tag and 'datetime' in time_tag.attrs else ''
                        if date_str:
                            try:
                                date_obj = datetime.strptime(date_str[:19], "%Y-%m-%dT%H:%M:%S")
                                date_obj = date_obj.replace(tzinfo=pytz.UTC).astimezone(pytz.timezone("Asia/Shanghai"))
                                formatted_date = date_obj.strftime("%Y-%m-%d %H:%M")
                            except:
                                formatted_date = date_str
                        else:
                            formatted_date = ""

                        # å¤„ç†å›¾ç‰‡
                        img = item.find('img')
                        image = (img.get('data-src') or img.get('src') or '').split('?')[0]

                        all_results.append({
                            'title': title,
                            'link': link,
                            'date': formatted_date,
                            'image': image
                        })
                    except Exception as e:
                        print(f"æ¡ç›®è§£æå¤±è´¥: {str(e)[:50]}...")
                        continue

                break  # æˆåŠŸåˆ™è·³å‡ºé‡è¯•å¾ªç¯

            except Exception as e:
                retry_count += 1
                print(f"ç¬¬ {retry_count} æ¬¡é‡è¯•ï¼Œé”™è¯¯: {str(e)[:100]}...")
                if retry_count == max_retries:
                    print(f"âš ï¸ é¡µé¢ {page_num} æŠ“å–å¤±è´¥ï¼Œè·³è¿‡")
                time.sleep(random.uniform(5, 10))

        # éšæœºå»¶è¿Ÿï¼ˆæ›´è‡ªç„¶ï¼‰
        if page_num < pages_to_crawl:
            delay = random.uniform(5, 15)
            print(f"ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
            time.sleep(delay)

    # å…³é—­æµè§ˆå™¨
    context.close()
    browser.close()

# ä¿å­˜ç»“æœ
current_time = datetime.now(pytz.timezone("Asia/Shanghai")).strftime('%Y-%m-%d %H:%M')
with open("results.json", "w", encoding="utf-8") as f:
    json.dump(all_results, f, ensure_ascii=False, indent=2)

with open("switch_news.md", "w", encoding="utf-8") as f:
    f.write(f"# Nintendo Switch æ¸¸æˆä¿¡æ¯\næ›´æ–°æ—¶é—´ï¼š{current_time} (UTC+8)\n\n")
    if all_results:
        f.write(f"âœ… å…±æŠ“å– {len(all_results)} æ¡æ¸¸æˆä¿¡æ¯ï¼ˆæ¥è‡ª {pages_to_crawl} é¡µï¼‰:\n\n")
        for idx, game in enumerate(all_results, 1):
            f.write(f"{idx}. [{game['title']}]({game['link']})")
            if game['date']:
                f.write(f" - å‘å¸ƒæ—¶é—´: {game['date']}")
            if game['image']:
                f.write(f"\n   ![å°é¢]({game['image']})")
            f.write("\n")
    else:
        f.write("âŒ æœªè·å–åˆ°ä»»ä½•æ¸¸æˆä¿¡æ¯\n")

print(f"\nğŸ‰ å®Œæˆï¼å…±æŠ“å– {len(all_results)} æ¡æ•°æ®")
print(f"ğŸ“„ JSON æ–‡ä»¶: results.json")
print(f"ğŸ“ Markdown æ–‡ä»¶: switch_news.md")
