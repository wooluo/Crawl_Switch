import requests
from bs4 import BeautifulSoup
import json
import os

from datetime import datetime

base_url = "https://www.gamer520.com/switchyouxi"
for page in range(1, 6):
    url = f'{base_url}/page/{page}' if page > 1 else base_url
    results = []

import random
import time

user_agents = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:89.0) Gecko/20100101 Firefox/89.0'
]

headers = {
    'User-Agent': random.choice(user_agents),
    'Referer': 'https://www.gamer520.com/'
}

# éšæœºå»¶è¿Ÿ1-3ç§’
time.sleep(random.uniform(1, 3))
response = requests.get(url, headers=headers, timeout=10)
response.encoding = 'utf-8'
soup = BeautifulSoup(response.text, 'html.parser')

all_results = []
keywords = ["ä¸­æ–‡", "3A", "ä¸‹è½½"]

# è·å–æ¸¸æˆåˆ—è¡¨
game_items = soup.find_all('article', class_='post-grid')
print(f"ğŸ” æ‰¾åˆ° {len(game_items)} ä¸ªæ¸¸æˆæ¡ç›®")

for item in game_items:
    title = item.find('h2', class_='entry-title').get_text().strip() if item.find('h2', class_='entry-title') else ''
    href = item.find('a')['href'] if item.find('a') else ''
    date = item.find('time')['datetime'] if item.find('time') else ''
    image = item.find('img', class_='lazyload')['data-src'] if item.find('img', class_='lazyload') else ''
    
    # æ‰“å°è°ƒè¯•ä¿¡æ¯
    print(f"æ‰¾åˆ°æ¸¸æˆ: {title}")
    print(f"é“¾æ¥: {href}")
    print(f"å°é¢: {image}")
    
    if title and href:  # ç§»é™¤å…³é”®è¯è¿‡æ»¤ï¼Œå› ä¸ºæ‰€æœ‰æ¡ç›®éƒ½åœ¨switchæ¸¸æˆä¸‹è½½åˆ†ç±»ä¸‹
        # æ·»åŠ è°ƒè¯•ä¿¡æ¯
        print(f"ğŸ” å¤„ç†æ¡ç›®: {title}")
        print(f"  é“¾æ¥: {href}")
        print(f"  åŒ¹é…ç»“æœ: {any(keyword.lower() in title.lower() for keyword in keywords)}")
        results.append({
            'title': title,
            'link': href,
            'date': date,
            'image': image
        })
        if results:
            all_results.extend(results)

# å†™å…¥ JSON
with open("results.json", "w", encoding="utf-8") as f:
    json.dump(all_results, f, ensure_ascii=False, indent=2)

# å†™å…¥ Markdown
md_file = "switch_news.md"
# ä¿®æ”¹å†™å…¥Markdownæ–‡ä»¶çš„ä»£ç éƒ¨åˆ†
with open('switch_news.md', 'w', encoding='utf-8') as f:
    f.write(f"# Nintendo Switch æ¸¸æˆä¿¡æ¯\næ›´æ–°æ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M')}\n\n")
    for game in all_results:
        # ç¡®ä¿å­—å…¸ä¸­æœ‰éœ€è¦çš„é”®
        if 'title' in game and 'href' in game and 'cover' in game:
            f.write(f"æ‰¾åˆ°æ¸¸æˆ: {game['title']}\n")
            # ä¿®æ”¹å°é¢å›¾ç‰‡å†™å…¥éƒ¨åˆ†
             # æˆ–è€…å¦‚æœæ‚¨æƒ³æ§åˆ¶å›¾ç‰‡å¤§å°
            f.write(f"å°é¢: (`{game['cover']}`)\n")
            f.write(f"é“¾æ¥: `{game['href']}`\n")
            f.write(f"ğŸ” å¤„ç†æ¡ç›®: {game['title']}\n")
            f.write(f"  é“¾æ¥: `{game['href']}`\n")
    f.write(f"âœ… å…±æ‰¾åˆ° {len(all_results)} æ¡ Nintendo Switch æ¸¸æˆä¿¡æ¯")
    if all_results:
        f.write(f"å…±æ‰¾åˆ° {len(all_results)} æ¡æ¸¸æˆä¿¡æ¯ï¼š\n\n")
        for item in all_results:
            f.write(f"- [{item['title']}]\nä¸‹è½½é“¾æ¥ï¼š({item['link']})\n![æ¸¸æˆæˆªå›¾]({item['image']})\n")
    else:
        f.write("âŒ å½“å‰æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¸ Nintendo Switch æ¸¸æˆä¿¡æ¯ã€‚\n")

if all_results:
    print(f"âœ… æˆåŠŸæ‰¾åˆ° {len(all_results)} æ¡ Nintendo Switch æ¸¸æˆä¿¡æ¯ (å…±æŠ“å– {page} é¡µ)")
else:
    print("âŒ æ²¡æœ‰æ‰¾åˆ°ä»»ä½• Nintendo Switch æ¸¸æˆä¿¡æ¯")
    print("âš ï¸ è°ƒè¯•ä¿¡æ¯:")
    print(f"- å“åº”çŠ¶æ€ç : {response.status_code}")
    print(f"- æ‰¾åˆ°çš„æ¸¸æˆæ¡ç›®æ•°: {len(game_items)}")
    if game_items:
        first_item = game_items[0]
        print(f"- ç¬¬ä¸€ä¸ªæ¡ç›®å†…å®¹ç¤ºä¾‹: {str(first_item)[:200]}...")
    print(f"- é¡µé¢æ ‡é¢˜: {soup.title.string if soup.title else 'æ— æ ‡é¢˜'}")
