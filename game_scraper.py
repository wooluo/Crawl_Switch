import logging
import os
from playwright.sync_api import sync_playwright
from bs4 import BeautifulSoup
import json
from datetime import datetime
import time
import random
import pytz

# é…ç½®æ—¥å¿—è®°å½•
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# åŠ è½½é…ç½®æ–‡ä»¶
def load_config():
    try:
        with open('config.json', 'r', encoding='utf-8') as f:
            return json.load(f)
    except FileNotFoundError:
        logging.error("é…ç½®æ–‡ä»¶ config.json æœªæ‰¾åˆ°ã€‚")
        return {}

CONFIG = load_config()
USER_AGENTS = CONFIG.get('user_agents', [])

def get_timestamp():
    """è·å–å½“å‰æ—¶é—´æˆ³"""
    return datetime.now(pytz.timezone("Asia/Shanghai")).strftime('%Y%m%d_%H%M%S')

def save_results(data):
    """ä¿å­˜ç»“æœåˆ°æ–‡ä»¶"""
    timestamp = get_timestamp()
    json_filename = f"results_{timestamp}.json"
    md_filename = f"switch_news_{timestamp}.md"
    current_time = datetime.now(pytz.timezone("Asia/Shanghai")).strftime('%Y-%m-%d %H:%M')

    # ä¿å­˜JSONæ–‡ä»¶
    try:
        with open(json_filename, "w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logging.error(f"ä¿å­˜JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None, None

    # ç”ŸæˆMarkdownæ–‡ä»¶
    try:
        with open(md_filename, "w", encoding="utf-8") as f:
            f.write(f"# Nintendo Switch æ¸¸æˆä¿¡æ¯\næ›´æ–°æ—¶é—´ï¼š{current_time} (UTC+8)\n\n")
            if data:
                f.write(f"âœ… å…±æ‰¾åˆ° {len(data)} æ¡æ¸¸æˆä¿¡æ¯ï¼š\n\n")
                for game in data:
                    f.write(f"- [{game['title']}]({game['link']})")
                    if game['image']:
                        f.write(f"\n  ![å°é¢]({game['image']})")
                    f.write("\n")
            else:
                f.write("âŒ å½“å‰æ²¡æœ‰æ‰¾åˆ°ä»»ä½•ä¸ Nintendo Switch ç›¸å…³çš„æ¸¸æˆä¿¡æ¯ã€‚\n")
    except Exception as e:
        logging.error(f"ç”ŸæˆMarkdownæ–‡ä»¶æ—¶å‡ºé”™: {e}")
        return None, None

    logging.info(f"ğŸ‰ æ•°æ®å·²ä¿å­˜è‡³ {json_filename} å’Œ {md_filename}")
    return json_filename, md_filename

def extract_game_info(html):
    soup = BeautifulSoup(html, 'html.parser')
    game_articles = soup.find_all('article', class_=lambda x: x and 'post' in x)
    results = []

    for article in game_articles:
        try:
            # æå–æ¸¸æˆåç§°
            title = article.find('h2', class_='entry-title').a.get_text().strip()

            # æå–æ¸¸æˆå›¾ç‰‡
            img = article.find('img', class_='lazyload')
            image = img.get('data-src') if img else ''

            # æå–æ¸¸æˆé“¾æ¥
            link = article.find('h2', class_='entry-title').a['href']

            if title and link:
                results.append({
                    'title': title,
                    'image': image,
                    'link': link
                })
        except Exception as e:
            logging.warning(f"è§£ææ¸¸æˆä¿¡æ¯æ—¶å‡ºé”™: {e}")

    return results

def scrape_page(page, url, attempt=1):
    """æŠ“å–å•ä¸ªé¡µé¢"""
    try:
        # éšæœºå»¶è¿Ÿé¿å…è¢«å±è”½
        time.sleep(random.uniform(CONFIG.get('min_delay', 3), CONFIG.get('max_delay', 8)))

        # è®¿é—®é¡µé¢
        page.goto(
            url,
            timeout=CONFIG.get('timeout', 45000),
            wait_until="networkidle"  # æ›´å®½æ¾çš„ç­‰å¾…æ¡ä»¶
        )

        # ç­‰å¾…ä¸»è¦å†…å®¹åŠ è½½
        page.wait_for_selector("article.post", timeout=20000)

        # æ»šåŠ¨é¡µé¢è§¦å‘æ‡’åŠ è½½
        for _ in range(3):
            page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
            time.sleep(random.uniform(1, 3))

        # è·å–é¡µé¢å†…å®¹
        html = page.content()
        game_info = extract_game_info(html)
        logging.info(f"ğŸ” æ‰¾åˆ° {len(game_info)} ä¸ªæ¸¸æˆæ¡ç›®")

        return game_info

    except Exception as e:
        logging.warning(f"âš ï¸ ç¬¬ {attempt} æ¬¡å°è¯•å¤±è´¥: {str(e)[:200]}...")
        if attempt < CONFIG.get('max_retries', 3):
            time.sleep(CONFIG.get('retry_delay', 5))
            return scrape_page(page, url, attempt + 1)
        else:
            logging.error(f"âŒ é¡µé¢æŠ“å–å¤±è´¥: {url}")
            return []

def main():
    # æ£€æŸ¥å¹¶å®‰è£…æµè§ˆå™¨
    if not os.path.exists(os.path.expanduser('~/.cache/ms-playwright')):
        logging.info("Playwright æµè§ˆå™¨æœªå®‰è£…ï¼Œæ­£åœ¨å®‰è£…...")
        os.system("playwright install")
        logging.info("Playwright æµè§ˆå™¨å®‰è£…å®Œæˆã€‚")

    all_results = []

    with sync_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨
        browser = p.chromium.launch(
            headless=True,
            args=[
                '--disable-blink-features=AutomationControlled',
                '--no-sandbox',
                '--disable-dev-shm-usage'  # é’ˆå¯¹Dockerç¯å¢ƒçš„ä¼˜åŒ–
            ]
        )

        # åˆ›å»ºä¸Šä¸‹æ–‡
        context = browser.new_context(
            user_agent=random.choice(USER_AGENTS),
            viewport={'width': 1920, 'height': 1080}
        )
        page = context.new_page()

        try:
            url = CONFIG.get('base_url', 'https://www.gamer520.com/gameswitch')
            logging.info(f"\næ­£åœ¨è®¿é—®é¡µé¢: {url}")

            # åœ¨GitHub Actionsç¯å¢ƒä¸­ä¿å­˜è°ƒè¯•æˆªå›¾
            if os.getenv('GITHUB_ACTIONS') == 'true':
                page.screenshot(path="debug_page.png")
                logging.info("å·²ä¿å­˜è°ƒè¯•æˆªå›¾")

            page_results = scrape_page(page, url)
            all_results.extend(page_results)

        except Exception as e:
            logging.error(f"å‘ç”Ÿå¼‚å¸¸: {str(e)}")
        finally:
            # ç¡®ä¿èµ„æºé‡Šæ”¾
            context.close()
            browser.close()

    # ä¿å­˜ç»“æœ
    json_file, md_file = save_results(all_results)

    # è¾“å‡ºæ€»æŠ“å–æ•°é‡
    if json_file and os.path.exists(json_file):
        try:
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            logging.info(f"ğŸ“Š æ€»æŠ“å–æ•°é‡: {len(data)}")
        except Exception as e:
            logging.error(f"è¯»å–JSONæ–‡ä»¶æ—¶å‡ºé”™: {e}")
    else:
        logging.info("ğŸ“Š æ²¡æœ‰æŠ“å–åˆ°ä»»ä½•æ•°æ®")

if __name__ == "__main__":
    start_time = time.time()
    main()
    logging.info(f"â±ï¸ æ€»è€—æ—¶: {time.time() - start_time:.2f}ç§’")